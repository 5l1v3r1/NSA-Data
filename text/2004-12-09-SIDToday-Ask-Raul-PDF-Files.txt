DYNAMIC PAGE -- HIGHEST POSSIBLE CLASSIFICATION IS<br>TOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL<br><br>(U) Ask Raul: PDF Files<br>FROM: Raul, a DNI Analyst<br>Unknown<br>Run Date: 12/09/2004<br><br>Dear Raul,<br>(C) I get a fair number of PDF files in my DNI collection and when<br>they are good, they're great. However, when they are even the<br>least bit damaged there isn't a thing I can do. Sometimes, I'll try to<br>load one and it will flash something at me from the Acrobat Reader<br>and then it's gone. It looks like stuff should be coming out but all I<br>end up with is an error message. What's up with these things?<br>Rachel<br>Dear Rachel,<br>(U) I love PDF. Portable Document Format from Adobe is one of the<br>neatest document formats around. If it is an indication of anything,<br>the current PDF specification document, for version 1.6, is over<br>1200 pages long. First, a bit of explanation on how it works.<br>(U) All PDF files are basically archives. The document is divided up<br>into objects that are generally text, images, fonts, and encoding<br>tables. Each of these objects can be encoded, compressed and/or<br>encrypted. Generally speaking though, they are usually just<br>compressed using a well-known method. Additionally, there is a<br>structure within the file that tells where all the objects are. There's<br>a whole lot of stuff going on inside these files but this is a<br>reasonable enough basic explanation.<br>(U) So, here is a little example of an object:<br><br>Obviously, whatever happens to be inside this little blob of binary is<br>not going to be something we can select against and especially not<br>if it is underneath some other compression, encoding or both (i.e.<br>zip, base64). Fortunately, Adobe is nice enough to tell us exactly<br>which compression is being used (Flate) so decompressing this is a<br>snap and here is what it looks like:<br><br>That's a bit better but as you can see, the text is a bit of a mess.<br>That is because it is formatted for display. The real text is all of the<br>material in parentheses. As you can see, some words are all in one<br>piece while others have been separated in what appear to be some<br>very strange ways. Notice how the word "love" was turned into<br>(l)0(o)16(v)15(e). Therefore, the next thing we want to do is to<br>take care of this formatting, which is a piece of cake, and turn this<br>text back into a form we can search against it or read. If you'll<br>notice, this is just the first paragraph of this article.<br>(U) So, now you see that to properly process a PDF document<br><br> SERIES: <br>(U) Ask Raul - Answers<br>to DNI Questions<br>1.  Ask Raul : Fonts and<br>Encoding<br>2.  Ask Raul : Dictionary<br>Equations<br>3.  Ask Raul : HTML<br>Coding and Email<br>4.  Ask Raul : PDF Files<br>5.  Ask Raul: Damaged<br>Data<br>6.  Ask Raul : Getting<br>the Most from<br>Metadata<br><br> </p>containing English text you'll have to:<br>1.  Find the objects containing something of value (text, image,<br>whatever).<br>2.  Decompress, decode and/or decipher the object.<br>3.  Remove the formatting from the text.<br>Seems simple enough but some PDF documents can have hundreds<br>or thousands of objects. This means, potentially, a whole lot of<br>decoding, decompressing and/or decryption. But it gets better!<br>(S) Take a peep at this:<br><br>Beautiful, isn't it? You could use everything available to you here<br>at NSA. Put in all of these words into a dictionary in every possible<br>character set and guess what? You'll never get a hit against this<br>document. Why? Here you go.<br>(U) When we move outside of English with PDF, some very<br>interesting and intelligent things get done. The designers of PDF<br>looked at the problem like this:<br>Hmmm. We'll, we could include whole fonts for particular character<br>sets and deal with multiple character set encodings but man, even<br>a font for an 8-bit character set is huge and if we take on<br>languages like Chinese, Japanese and Korean, well, things just get<br>much worse and our files will be humongous. Let's see. Wait a<br>minute! I've got it. Instead of sending the entire font, let's see<br>which characters we actually used and only send those. Brilliant!<br>And better yet, we'll compress all this stuff and when we're<br>through, the file will be much smaller. Great! We are good!<br>(S) So, in order to perform this magical trick, they re-encode the<br>text and create an encoding table that maps the new encoding to<br>some known encoding. This being the case, in order to convert the<br>underlying text back into something we can select against, we<br>have to find these encoding tables and apply them to the encoded<br>text in the appropriate object so as to render them in a form we<br>can actually select against. Better still, each object might have had<br>characters which came from multiple fonts so that we would then<br>have to know about all the other encoding tables used by that<br>object in order to re-encode it properly.<br>(C) Now, you say, "Great Raul! That's what we're doing, right?"<br>Sadly enough, the answer is no. Worse still, no consideration has<br>been given to the fact that the vast majority of the PDF files we run<br>across are of such a form that we could, if we were so inclined,<br>split them up and reassemble them as we saw fit. Yes, you see<br>where I'm going here, don't you? If we can do this, it also means<br>we should be able to deal with broken or damaged PDF files with<br>great ease. Again, unfortunately, the sad truth is we can't do that<br>either. It really isn't even a matter of our not being able to do it as<br>much as one of simply not having done it. And PDF's aren't the<br>only things we have this trouble with as you well know.<br>(C) So, there you go. Think of it like this:<br>If you were looking for Osama bin Laden, and you had entered<br>every Arabic word known to mankind in every possible encoding<br>and Osama were doing nothing more than using PDF and writing in<br><br> </p>Arabic, you'd never get a hit. Quite reassuring, isn't it?<br>Raul<br><br>"(U//FOUO) SIDtoday articles may not be republished or reposted outside NSANet<br>without the consent of S0121 (DL sid_comms)."<br><br>DYNAMIC PAGE -- HIGHEST POSSIBLE CLASSIFICATION IS<br>TOP SECRET // SI / TK // REL TO USA AUS CAN GBR NZL<br>DERIVED FROM: NSA/CSSM 1-52, DATED 08 JAN 2007 DECLASSIFY ON: 20320108<br><br> </p>